# EduTrack ğŸ“  
*A Smart Platform for Tracking Student Attentiveness in Online Learning*  

EduTrack is a **full-stack web platform** that helps teachers monitor and evaluate student attentiveness while learning online. Using a deep learning model with live video analysis, EduTrack classifies students as **Attentive** or **Distracted** during study sessions.  

---

## ğŸ‘¥ User Roles  
- Superuser â†’ manages teachers.  
- Teacher â†’ manages students, courses, learning materials, and monitors attentiveness.  
- Student â†’ accesses assigned courses and study materials.  

---

## ğŸš€ Features  

### ğŸ”‘ Authentication & Profiles  
- Superuser â†’ can add/view teachers.  
- Teacher â†’ can add/view students.  
- Students & Teachers â†’ can update profile and change password.  

### ğŸ“š Course Management  
- Teachers can add courses and upload PDF materials.  
- Teachers can assign materials to students.  
- Teachers can track student progress (time spent, attentiveness %, distraction %).  

### ğŸ‘€ Attentiveness Detection  
- When a student opens a material, their webcam is activated.  
- Every 5 seconds, an image is sent from frontend â†’ backend.  
- Deep learning model analyzes frames:  
  - Attentive â†’ looking at screen.  
  - Distracted â†’ using phone, looking away, covering face, etc.  
- Results are logged per material and aggregated in teacher dashboards.  

### ğŸ“Š Analytics  
- Teachers can see per-student stats:  
  - Total time spent learning.  
  - Attentive % vs Distracted %.  

---

## ğŸ§  Deep Learning Model  

### Dataset  
- Collected videos of 10+ people attending online classes.  
- Collected selfie videos/images from Kaggle & Roboflow.  
- Extracted frames (every 5th frame at 30 fps).  
- Cropped images to face + upper shoulder.  

**Final dataset**:  
- 900 Attentive images  
- 900 Distracted images  

### Training  
- Model: MobileNetV2 (transfer learning).  
- Input size: 224Ã—224.  
- Techniques: Data Augmentation (rotation, brightness, zoom, blur), Dropout (0.4â€“0.5), Learning Rate tuning (1e-4 â†’ 1e-5).  

### Results  
- Accuracy: ~87% on validation set.  

### Live Performance  
- Detects distractions like phone use, looking away, or covering face.  

---

## ğŸ› ï¸ Tech Stack  
- Frontend â†’ React (Vite)  
- Backend â†’ Django, Django REST Framework  
- Database â†’ PostgreSQL  
- Model Training â†’ TensorFlow / Keras (MobileNetV2)  

---

## âš¡ How to Run  

### 1. Clone repo  
```bash
git clone https://github.com/yourusername/edutrack.git
cd edutrack
```
### 2. Backend setup (Django)
```bash
cd backend
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

pip install -r requirements.txt
python manage.py migrate
python manage.py createsuperuser
python manage.py runserver
```
### 3. Frontend setup (React + Vite)
```bash
cd client
npm install
npm run dev
```
### ğŸ“ˆ Future Improvements

- Expand dataset with more people, varied backgrounds & lighting.
- Use head pose & eye gaze tracking for better accuracy.
- Deploy as Dockerized full-stack app.
